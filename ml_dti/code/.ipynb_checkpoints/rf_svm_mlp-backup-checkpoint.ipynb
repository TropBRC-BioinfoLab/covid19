{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1274</th>\n",
       "      <th>1275</th>\n",
       "      <th>1276</th>\n",
       "      <th>1277</th>\n",
       "      <th>1278</th>\n",
       "      <th>1279</th>\n",
       "      <th>1280</th>\n",
       "      <th>1281</th>\n",
       "      <th>1282</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6435415</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146655</td>\n",
       "      <td>0.102916</td>\n",
       "      <td>0.030875</td>\n",
       "      <td>0.210120</td>\n",
       "      <td>0.097770</td>\n",
       "      <td>0.191252</td>\n",
       "      <td>0.054889</td>\n",
       "      <td>Q59FK4_HUMAN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2585</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123913</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.039130</td>\n",
       "      <td>0.106522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.969565</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>CP1B1_HUMAN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>445154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.214689</td>\n",
       "      <td>0.150659</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.184557</td>\n",
       "      <td>0.214689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.421846</td>\n",
       "      <td>UD15_HUMAN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10127622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163599</td>\n",
       "      <td>0.073620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261759</td>\n",
       "      <td>CP2C9_HUMAN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3736</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052189</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>0.044228</td>\n",
       "      <td>0.071650</td>\n",
       "      <td>0.195046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147943</td>\n",
       "      <td>0.084918</td>\n",
       "      <td>ENPP1_HUMAN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7    8    9  ...      1274  \\\n",
       "0   6435415  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "1      2585  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "2    445154  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.444444   \n",
       "3  10127622  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "4      3736  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.052189   \n",
       "\n",
       "       1275      1276      1277      1278      1279      1280      1281  \\\n",
       "0  0.146655  0.102916  0.030875  0.210120  0.097770  0.191252  0.054889   \n",
       "1  0.123913  0.043478  0.039130  0.106522  0.000000  0.969565  0.069565   \n",
       "2  0.214689  0.150659  0.067797  0.184557  0.214689  0.000000  0.421846   \n",
       "3  0.000000  0.163599  0.073620  0.000000  0.000000  0.000000  0.261759   \n",
       "4  0.075630  0.044228  0.071650  0.195046  0.000000  0.147943  0.084918   \n",
       "\n",
       "           1282  label  \n",
       "0  Q59FK4_HUMAN      0  \n",
       "1   CP1B1_HUMAN      0  \n",
       "2    UD15_HUMAN      0  \n",
       "3   CP2C9_HUMAN      0  \n",
       "4   ENPP1_HUMAN      0  \n",
       "\n",
       "[5 rows x 1284 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data2/latih_parted.csv\", delimiter=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df\n",
    "#del dataset[0]\n",
    "#del dataset[1282]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['0','1282','label'], axis=1)\n",
    "Y = df['label']\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1273</th>\n",
       "      <th>1274</th>\n",
       "      <th>1275</th>\n",
       "      <th>1276</th>\n",
       "      <th>1277</th>\n",
       "      <th>1278</th>\n",
       "      <th>1279</th>\n",
       "      <th>1280</th>\n",
       "      <th>1281</th>\n",
       "      <th>1282</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4725</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088155</td>\n",
       "      <td>0.067198</td>\n",
       "      <td>0.051936</td>\n",
       "      <td>0.031891</td>\n",
       "      <td>0.053303</td>\n",
       "      <td>0.223235</td>\n",
       "      <td>0.493394</td>\n",
       "      <td>0.025399</td>\n",
       "      <td>0.065604</td>\n",
       "      <td>K4LC41_9BETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4725</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187898</td>\n",
       "      <td>0.181529</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.312102</td>\n",
       "      <td>0.363057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203822</td>\n",
       "      <td>PLpro_SARS-CoV-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4725</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281967</td>\n",
       "      <td>0.193443</td>\n",
       "      <td>0.373770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118033</td>\n",
       "      <td>0.160656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209836</td>\n",
       "      <td>6LU7:A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4725</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.196013</td>\n",
       "      <td>0.189369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119601</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.378738</td>\n",
       "      <td>0.185216</td>\n",
       "      <td>0.053156</td>\n",
       "      <td>6M0J:A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4725</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144295</td>\n",
       "      <td>0.197987</td>\n",
       "      <td>0.191275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120805</td>\n",
       "      <td>0.082215</td>\n",
       "      <td>0.382550</td>\n",
       "      <td>0.187080</td>\n",
       "      <td>0.053691</td>\n",
       "      <td>6LZG:A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1283 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9  ...      1273      1274  \\\n",
       "0  4725  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.088155  0.067198   \n",
       "1  4725  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000  0.187898   \n",
       "2  4725  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.281967  0.193443   \n",
       "3  4725  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.142857  0.196013   \n",
       "4  4725  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.144295  0.197987   \n",
       "\n",
       "       1275      1276      1277      1278      1279      1280      1281  \\\n",
       "0  0.051936  0.031891  0.053303  0.223235  0.493394  0.025399  0.065604   \n",
       "1  0.181529  0.063694  0.000000  0.312102  0.363057  0.000000  0.203822   \n",
       "2  0.373770  0.000000  0.118033  0.160656  0.000000  0.000000  0.209836   \n",
       "3  0.189369  0.000000  0.119601  0.081395  0.378738  0.185216  0.053156   \n",
       "4  0.191275  0.000000  0.120805  0.082215  0.382550  0.187080  0.053691   \n",
       "\n",
       "               1282  \n",
       "0      K4LC41_9BETC  \n",
       "1  PLpro_SARS-CoV-2  \n",
       "2            6LU7:A  \n",
       "3            6M0J:A  \n",
       "4            6LZG:A  \n",
       "\n",
       "[5 rows x 1283 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = pd.read_csv(\"../data2/allneg_latih.csv\", delimiter=',')\n",
    "cf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf['label']=0\n",
    "cX = np.array(cf.drop(['0','1282','label'], axis=1))\n",
    "cY = cf['label']\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = dataset.iloc[:,0:1281]\n",
    "#Y = dataset.iloc[:, 1281]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pylab as pl\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "# validation_size = \n",
    "# seed = 7\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.9, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = rf.drop([0,1282,1283], axis=1)\n",
    "#Y_test = df[1283]\n",
    "#idcom = df[0]\n",
    "#idprot = df[1282]\n",
    "#seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6748, 1281)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('../data2/ujimbafikanorm.csv', delimiter= \",\", header=None)\n",
    "df0=df0.fillna(0)\n",
    "ddfcom=df0[0]\n",
    "ddfprot=df0[1282]\n",
    "del df0[0]\n",
    "del df0[1282]\n",
    "x = np.array(df0)\n",
    "#scaler = MinMaxScaler()\n",
    "#x = scaler.fit_transform(x)\n",
    "df0[1300]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../data2/ujimbalindanorm.csv', delimiter= \",\", header=None)\n",
    "df1=df1.fillna(0)\n",
    "df1com=df1[0]\n",
    "df1prot=df1[1282]\n",
    "del df1[0]\n",
    "del df1[1282]\n",
    "x1 = np.array(df1)\n",
    "#scaler = MinMaxScaler()\n",
    "#x = scaler.fit_transform(x)\n",
    "df1[1300]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.03125, 0.125, 0.5, 2, 8, 32, 128, 512, 2048,\n",
       "                               8192, 32768],\n",
       "                         'gamma': [8, 2, 0.5, 0.125, 0.03125, 0.0078125,\n",
       "                                   0.001953125, 0.00048828125, 0.00012207031,\n",
       "                                   3.051757e-05],\n",
       "                         'kernel': ['rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_space0 = {\n",
    "    'C': [0.03125, 0.125, 0.5, 2, 8, 32, 128, 512, 2048, 8192, 32768],\n",
    "    'kernel': ['rbf'],#, 'sigmoid', 'poly','linear'],\n",
    "    'gamma' : [8, 2, 0.5, 0.125, 0.03125, 0.0078125, 0.001953125, 0.00048828125, 0.00012207031, 0.00003051757],\n",
    "}\n",
    "classifier0 = svm.SVC()\n",
    "classifier0 = GridSearchCV(classifier0, parameter_space0, n_jobs=-1, cv=5)\n",
    "classifier0.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[9780]]\n"
     ]
    }
   ],
   "source": [
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = classifier0.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameter_space1 = {\n",
    "    'C': [0.03125, 0.125, 0.5, 2, 8, 32, 128, 512, 2048, 8192, 32768],\n",
    "    'kernel': ['poly'],\n",
    "    'gamma' : [8, 2, 0.5, 0.125, 0.03125, 0.0078125, 0.001953125, 0.00048828125, 0.00012207031, 0.00003051757],\n",
    "}\n",
    "classifier1 = svm.SVC()\n",
    "classifier1 = GridSearchCV(classifier1, parameter_space1, n_jobs=-1, cv=5)\n",
    "classifier1.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = classifier1.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameter_space2 = {\n",
    "    'C': [0.03125, 0.125, 0.5, 2, 8, 32, 128, 512, 2048, 8192, 32768],\n",
    "    'kernel': ['sigmoid'],\n",
    "    'gamma' : [8, 2, 0.5, 0.125, 0.03125, 0.0078125, 0.001953125, 0.00048828125, 0.00012207031, 0.00003051757],\n",
    "}\n",
    "classifier2 = svm.SVC()\n",
    "classifier2 = GridSearchCV(classifier2, parameter_space2, n_jobs=-1, cv=5)\n",
    "classifier2.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = classifier2.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameter_space3 = {\n",
    "    'C': [0.03125, 0.125, 0.5, 2, 8, 32, 128, 512, 2048, 8192, 32768],\n",
    "    'kernel': ['linear'],\n",
    "    #'gamma' : [8, 2, 0.5, 0.125, 0.03125, 0.0078125, 0.001953125, 0.00048828125, 0.00012207031, 0.00003051757],\n",
    "}\n",
    "classifier3 = svm.SVC()\n",
    "classifier3 = GridSearchCV(classifier3, parameter_space3, n_jobs=-1, cv=5)\n",
    "classifier3.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = classifier3.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [1000]#int(x) for x in np.linspace(start = 100, stop = 300, num = 3)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto']#, None]\n",
    "# Maximum number of levels in tree\n",
    "#max_depth = []#int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "#max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1]#hal 2 lit review\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "random_grid = {'n_estimators': [1000],\n",
    "               'max_features': ['auto'],\n",
    "               #'max_depth': max_depth,\n",
    "               'min_samples_split': [2],\n",
    "               'min_samples_leaf': [1],\n",
    "               'bootstrap': [True]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(n):\n",
    "    random_grid = {'n_estimators': [n],\n",
    "                   'max_features': ['auto'],\n",
    "                   #'max_depth': max_depth,\n",
    "                   'min_samples_split': [2],\n",
    "                   'min_samples_leaf': [1],\n",
    "                   'bootstrap': [True]}\n",
    "    rf = RandomForestClassifier()\n",
    "    rf = GridSearchCV(rf, random_grid, n_jobs=-1, cv=5)\n",
    "    rf.fit(X, Y)\n",
    "    filename = '../data2/model/RF_%sn' % (n)\n",
    "    pickle.dump(rf, open(filename, 'wb'))\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True], 'max_features': ['auto'],\n",
       "                         'min_samples_leaf': [1], 'min_samples_split': [2],\n",
       "                         'n_estimators': [1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_grid = {'n_estimators': [1000],\n",
    "               'max_features': ['auto'],\n",
    "               #'max_depth': max_depth,\n",
    "               'min_samples_split': [2],\n",
    "               'min_samples_leaf': [1],\n",
    "               'bootstrap': [True]}\n",
    "rf = RandomForestClassifier()\n",
    "rf = GridSearchCV(rf, random_grid, n_jobs=-1, cv=5)\n",
    "rf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'GridSearchCV' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-222c00efd6f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'GridSearchCV' object is not callable"
     ]
    }
   ],
   "source": [
    "rf=rf(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_report(rf):\n",
    "    rf = pickle.load(open('../data2/model/RF_%sn'%rf, 'rb'))\n",
    "    pred_x = rf.predict(X)\n",
    "    print('Accuracy:',accuracy_score(Y, pred_x))\n",
    "    print('f1:',f1_score(Y, pred_x))\n",
    "    print('precision:',precision_score(Y, pred_x))\n",
    "    print('recall:',recall_score(Y, pred_x))\n",
    "    print('roc_auc:',roc_auc_score(Y, pred_x))\n",
    "    print('Confusion matrix:')\n",
    "    print(confusion_matrix(Y, pred_x))\n",
    "    print('Results on the train set:')\n",
    "    print(classification_report(Y, pred_x))\n",
    "    pred_n = rf.predict(cX)\n",
    "    print('Results on the all neg data:')\n",
    "    print(classification_report(cY, pred_n))\n",
    "    print('Best parameters found:\\n', rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9925389510642967\n",
      "f1: 0.9747399702823181\n",
      "precision: 0.9924357034795764\n",
      "recall: 0.9576642335766423\n",
      "roc_auc: 0.9781864556312964\n",
      "Confusion matrix:\n",
      "[[3867    5]\n",
      " [  29  656]]\n",
      "Results on the train set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      3872\n",
      "           1       0.99      0.96      0.97       685\n",
      "\n",
      "    accuracy                           0.99      4557\n",
      "   macro avg       0.99      0.98      0.99      4557\n",
      "weighted avg       0.99      0.99      0.99      4557\n",
      "\n",
      "Results on the all neg data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     38727\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.98     38727\n",
      "   macro avg       0.50      0.49      0.49     38727\n",
      "weighted avg       1.00      0.98      0.99     38727\n",
      "\n",
      "Best parameters found:\n",
      " {'bootstrap': True, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rf_report(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_(mod,param):\n",
    "    mod(param)\n",
    "    rf_report(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datauji(data):    \n",
    "    df0 = pd.read_csv('../data2/uji%snorm.csv'%data, delimiter= \",\", header=None)\n",
    "    df0=df0.fillna(0)\n",
    "    ddfcom=df0[0]\n",
    "    ddfprot=df0[1282]\n",
    "    del df0[0]\n",
    "    del df0[1282]\n",
    "    x = np.array(df0)\n",
    "    #scaler = MinMaxScaler()\n",
    "    #x = scaler.fit_transform(x)\n",
    "    df0[1300]=0\n",
    "    return x, ddfcom, ddfprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mbafika' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-719695ac07c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdatauji\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmbafika\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mbafika' is not defined"
     ]
    }
   ],
   "source": [
    "datauji(mbafika)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pediksi(rf,data_uji)\n",
    "\n",
    "    #mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "    pred_x = rf.predict(x)\n",
    "    print(accuracy_score(df0[1300], pred_x))\n",
    "    print(confusion_matrix(df0[1300], pred_x))\n",
    "    pred_x = pd.DataFrame(pred_x)\n",
    "    pred_x[1] = ddfcom\n",
    "    pred_x[2] = ddfprot\n",
    "    pred_x.to_excel('../data2/hasil_pred/RF1000n_mbafika.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9936361641430765\n",
      "f1: 0.9785025945144551\n",
      "precision: 0.9939759036144579\n",
      "recall: 0.9635036496350365\n",
      "roc_auc: 0.9812352958918985\n",
      "Confusion matrix:\n",
      "[[3868    4]\n",
      " [  25  660]]\n",
      "Results on the train set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      3872\n",
      "           1       0.99      0.96      0.98       685\n",
      "\n",
      "    accuracy                           0.99      4557\n",
      "   macro avg       0.99      0.98      0.99      4557\n",
      "weighted avg       0.99      0.99      0.99      4557\n",
      "\n",
      "Results on the all neg data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     38727\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.98     38727\n",
      "   macro avg       0.50      0.49      0.49     38727\n",
      "weighted avg       1.00      0.98      0.99     38727\n",
      "\n",
      "Best parameters found:\n",
      " {'bootstrap': True, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model_(rf,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5041666666666667\n",
      "[[121 119]\n",
      " [  0   0]]\n"
     ]
    }
   ],
   "source": [
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = rf.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))\n",
    "pred_x = pd.DataFrame(pred_x)\n",
    "pred_x[1] = ddfcom\n",
    "pred_x[2] = ddfprot\n",
    "pred_x.to_excel('../data2/hasil_pred/RF1000n_mbafika.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[[120 120]\n",
      " [  0   0]]\n"
     ]
    }
   ],
   "source": [
    "random_grid = {'n_estimators': [2000],\n",
    "               'max_features': ['auto'],\n",
    "               #'max_depth': max_depth,\n",
    "               'min_samples_split': [2],\n",
    "               'min_samples_leaf': [1],\n",
    "               'bootstrap': [True]}\n",
    "rf2 = RandomForestClassifier()\n",
    "rf2 = GridSearchCV(rf2, random_grid, n_jobs=-1, cv=5)\n",
    "rf2.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[[120 120]\n",
      " [  0   0]]\n"
     ]
    }
   ],
   "source": [
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = rf2.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))\n",
    "pred_x = pd.DataFrame(pred_x)\n",
    "pred_x[1] = ddfcom\n",
    "pred_x[2] = ddfprot\n",
    "pred_x.to_excel('../data2/hasil_pred/RF2000n_mbafika.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[[120 120]\n",
      " [  0   0]]\n"
     ]
    }
   ],
   "source": [
    "random_grid = {'n_estimators': [500],\n",
    "               'max_features': ['auto'],\n",
    "               #'max_depth': max_depth,\n",
    "               'min_samples_split': [2],\n",
    "               'min_samples_leaf': [1],\n",
    "               'bootstrap': [True]}\n",
    "rf3 = RandomForestClassifier()\n",
    "rf3 = GridSearchCV(rf3, random_grid, n_jobs=-1, cv=5)\n",
    "rf3.fit(X, Y)\n",
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = rf3.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[[120 120]\n",
      " [  0   0]]\n"
     ]
    }
   ],
   "source": [
    "pred_x = rf3.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))\n",
    "pred_x = pd.DataFrame(pred_x)\n",
    "pred_x[1] = ddfcom\n",
    "pred_x[2] = ddfprot\n",
    "pred_x.to_excel('../data2/hasil_pred/RF500n_mbafika.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[[120 120]\n",
      " [  0   0]]\n"
     ]
    }
   ],
   "source": [
    "random_grid = {'n_estimators': [200],\n",
    "               'max_features': ['auto'],\n",
    "               #'max_depth': max_depth,\n",
    "               'min_samples_split': [2],\n",
    "               'min_samples_leaf': [1],\n",
    "               'bootstrap': [True]}\n",
    "rf4 = RandomForestClassifier()\n",
    "rf4 = GridSearchCV(rf4, random_grid, n_jobs=-1, cv=5)\n",
    "rf4.fit(X, Y)\n",
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = rf4.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[[120 120]\n",
      " [  0   0]]\n"
     ]
    }
   ],
   "source": [
    "pred_x = rf4.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))\n",
    "pred_x = pd.DataFrame(pred_x)\n",
    "pred_x[1] = ddfcom\n",
    "pred_x[2] = ddfprot\n",
    "pred_x.to_excel('../data2/hasil_pred/RF200n_mbafika.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5458333333333333\n",
      "[[131 109]\n",
      " [  0   0]]\n"
     ]
    }
   ],
   "source": [
    "random_grid = {'n_estimators': [100],\n",
    "               'max_features': ['auto'],\n",
    "               #'max_depth': max_depth,\n",
    "               'min_samples_split': [2],\n",
    "               'min_samples_leaf': [1],\n",
    "               'bootstrap': [True]}\n",
    "rf5 = RandomForestClassifier()\n",
    "rf5 = GridSearchCV(rf5, random_grid, n_jobs=-1, cv=5)\n",
    "rf5.fit(X, Y)\n",
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = rf5.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5458333333333333\n",
      "[[131 109]\n",
      " [  0   0]]\n"
     ]
    }
   ],
   "source": [
    "pred_x = rf5.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))\n",
    "pred_x = pd.DataFrame(pred_x)\n",
    "pred_x[1] = ddfcom\n",
    "pred_x[2] = ddfprot\n",
    "pred_x.to_excel('../data2/hasil_pred/RF100n_mbafika.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "[[144  96]\n",
      " [  0   0]]\n"
     ]
    }
   ],
   "source": [
    "random_grid = {'n_estimators': [10],\n",
    "               'max_features': ['auto'],\n",
    "               #'max_depth': max_depth,\n",
    "               'min_samples_split': [2],\n",
    "               'min_samples_leaf': [1],\n",
    "               'bootstrap': [True]}\n",
    "rf6 = RandomForestClassifier()\n",
    "rf6 = GridSearchCV(rf6, random_grid, n_jobs=-1, cv=5)\n",
    "rf6.fit(X, Y)\n",
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = rf6.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "[[144  96]\n",
      " [  0   0]]\n"
     ]
    }
   ],
   "source": [
    "pred_x = rf6.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))\n",
    "pred_x = pd.DataFrame(pred_x)\n",
    "pred_x[1] = ddfcom\n",
    "pred_x[2] = ddfprot\n",
    "pred_x.to_excel('../data2/hasil_pred/RF10n_mbafika.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5333333333333333\n",
      "[[128 112]\n",
      " [  0   0]]\n"
     ]
    }
   ],
   "source": [
    "random_grid = {'n_estimators': [50],\n",
    "               'max_features': ['auto'],\n",
    "               #'max_depth': max_depth,\n",
    "               'min_samples_split': [2],\n",
    "               'min_samples_leaf': [1],\n",
    "               'bootstrap': [True]}\n",
    "rf7 = RandomForestClassifier()\n",
    "rf7 = GridSearchCV(rf7, random_grid, n_jobs=-1, cv=5)\n",
    "rf7.fit(X, Y)\n",
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = rf7.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5333333333333333\n",
      "[[128 112]\n",
      " [  0   0]]\n"
     ]
    }
   ],
   "source": [
    "pred_x = rf7.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))\n",
    "pred_x = pd.DataFrame(pred_x)\n",
    "pred_x[1] = ddfcom\n",
    "pred_x[2] = ddfprot\n",
    "pred_x.to_excel('../data2/hasil_pred/RF50n_mbafika.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9995611147684881\n",
      "f1: 0.9985401459854014\n",
      "precision: 0.9985401459854014\n",
      "recall: 0.9985401459854014\n",
      "roc_auc: 0.9991409407612957\n",
      "Confusion matrix:\n",
      "[[3871    1]\n",
      " [   1  684]]\n",
      "Results on the train set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3872\n",
      "           1       1.00      1.00      1.00       685\n",
      "\n",
      "    accuracy                           1.00      4557\n",
      "   macro avg       1.00      1.00      1.00      4557\n",
      "weighted avg       1.00      1.00      1.00      4557\n",
      "\n",
      "Results on the all neg data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     38727\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.98     38727\n",
      "   macro avg       0.50      0.49      0.49     38727\n",
      "weighted avg       1.00      0.98      0.99     38727\n",
      "\n",
      "Best parameters found:\n",
      " {'bootstrap': True, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "all_report(rf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9995611147684881\n",
      "f1: 0.9985401459854014\n",
      "precision: 0.9985401459854014\n",
      "recall: 0.9985401459854014\n",
      "roc_auc: 0.9991409407612957\n",
      "Confusion matrix:\n",
      "[[3871    1]\n",
      " [   1  684]]\n",
      "Results on the train set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3872\n",
      "           1       1.00      1.00      1.00       685\n",
      "\n",
      "    accuracy                           1.00      4557\n",
      "   macro avg       1.00      1.00      1.00      4557\n",
      "weighted avg       1.00      1.00      1.00      4557\n",
      "\n",
      "Results on the all neg data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     38727\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.98     38727\n",
      "   macro avg       0.50      0.49      0.49     38727\n",
      "weighted avg       1.00      0.98      0.99     38727\n",
      "\n",
      "Best parameters found:\n",
      " {'bootstrap': True, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "all_report(rf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9995611147684881\n",
      "f1: 0.9985401459854014\n",
      "precision: 0.9985401459854014\n",
      "recall: 0.9985401459854014\n",
      "roc_auc: 0.9991409407612957\n",
      "Confusion matrix:\n",
      "[[3871    1]\n",
      " [   1  684]]\n",
      "Results on the train set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3872\n",
      "           1       1.00      1.00      1.00       685\n",
      "\n",
      "    accuracy                           1.00      4557\n",
      "   macro avg       1.00      1.00      1.00      4557\n",
      "weighted avg       1.00      1.00      1.00      4557\n",
      "\n",
      "Results on the all neg data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     38727\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.98     38727\n",
      "   macro avg       0.50      0.49      0.49     38727\n",
      "weighted avg       1.00      0.98      0.99     38727\n",
      "\n",
      "Best parameters found:\n",
      " {'bootstrap': True, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "all_report(rf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9995611147684881\n",
      "f1: 0.9985401459854014\n",
      "precision: 0.9985401459854014\n",
      "recall: 0.9985401459854014\n",
      "roc_auc: 0.9991409407612957\n",
      "Confusion matrix:\n",
      "[[3871    1]\n",
      " [   1  684]]\n",
      "Results on the train set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3872\n",
      "           1       1.00      1.00      1.00       685\n",
      "\n",
      "    accuracy                           1.00      4557\n",
      "   macro avg       1.00      1.00      1.00      4557\n",
      "weighted avg       1.00      1.00      1.00      4557\n",
      "\n",
      "Results on the all neg data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     38727\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.98     38727\n",
      "   macro avg       0.50      0.49      0.49     38727\n",
      "weighted avg       1.00      0.98      0.99     38727\n",
      "\n",
      "Best parameters found:\n",
      " {'bootstrap': True, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "all_report(rf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9945139346061005\n",
      "f1: 0.9814951887490748\n",
      "precision: 0.9954954954954955\n",
      "recall: 0.9678832116788321\n",
      "roc_auc: 0.9835542091452011\n",
      "Confusion matrix:\n",
      "[[3869    3]\n",
      " [  22  663]]\n",
      "Results on the train set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      3872\n",
      "           1       1.00      0.97      0.98       685\n",
      "\n",
      "    accuracy                           0.99      4557\n",
      "   macro avg       0.99      0.98      0.99      4557\n",
      "weighted avg       0.99      0.99      0.99      4557\n",
      "\n",
      "Results on the all neg data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     38727\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.98     38727\n",
      "   macro avg       0.50      0.49      0.49     38727\n",
      "weighted avg       1.00      0.98      0.99     38727\n",
      "\n",
      "Best parameters found:\n",
      " {'bootstrap': True, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "all_report(rf6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9995611147684881\n",
      "f1: 0.9985401459854014\n",
      "precision: 0.9985401459854014\n",
      "recall: 0.9985401459854014\n",
      "roc_auc: 0.9991409407612957\n",
      "Confusion matrix:\n",
      "[[3871    1]\n",
      " [   1  684]]\n",
      "Results on the train set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3872\n",
      "           1       1.00      1.00      1.00       685\n",
      "\n",
      "    accuracy                           1.00      4557\n",
      "   macro avg       1.00      1.00      1.00      4557\n",
      "weighted avg       1.00      1.00      1.00      4557\n",
      "\n",
      "Results on the all neg data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     38727\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.98     38727\n",
      "   macro avg       0.50      0.49      0.49     38727\n",
      "weighted avg       1.00      0.98      0.99     38727\n",
      "\n",
      "Best parameters found:\n",
      " {'bootstrap': True, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "all_report(rf7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True], 'max_features': ['auto'],\n",
       "                         'min_samples_leaf': [1], 'min_samples_split': [2],\n",
       "                         'n_estimators': [1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrandom_grid = {'n_estimators': [1000],\n",
    "               'max_features': ['auto'],\n",
    "               #'max_depth': max_depth,\n",
    "               'min_samples_split': [2],\n",
    "               'min_samples_leaf': [1],\n",
    "               'bootstrap': [True]}\n",
    "lrf = RandomForestClassifier()\n",
    "lrf = GridSearchCV(lrf, lrandom_grid, n_jobs=-1, cv=5)\n",
    "lrf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5006561679790026\n",
      "[[1526 1522]\n",
      " [   0    0]]\n"
     ]
    }
   ],
   "source": [
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = lrf.predict(x1)\n",
    "print(accuracy_score(df1[1300], pred_x))\n",
    "print(confusion_matrix(df1[1300], pred_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5006561679790026\n",
      "[[1526 1522]\n",
      " [   0    0]]\n"
     ]
    }
   ],
   "source": [
    "pred_x = lrf.predict(x1)\n",
    "print(accuracy_score(df1[1300], pred_x))\n",
    "print(confusion_matrix(df1[1300], pred_x))\n",
    "pred_x = pd.DataFrame(pred_x)\n",
    "pred_x[1] = df1com\n",
    "pred_x[2] = df1prot\n",
    "pred_x.to_excel('../data2/hasil_pred/RF1000n_mbalinda.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5003280839895013\n",
      "[[1525 1523]\n",
      " [   0    0]]\n"
     ]
    }
   ],
   "source": [
    "lrandom_grid = {'n_estimators': [2000],\n",
    "               'max_features': ['auto'],\n",
    "               #'max_depth': max_depth,\n",
    "               'min_samples_split': [2],\n",
    "               'min_samples_leaf': [1],\n",
    "               'bootstrap': [True]}\n",
    "lrf2 = RandomForestClassifier()\n",
    "lrf2 = GridSearchCV(lrf2, lrandom_grid, n_jobs=-1, cv=5)\n",
    "lrf2.fit(X, Y)\n",
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = lrf2.predict(x1)\n",
    "print(accuracy_score(df1[1300], pred_x))\n",
    "print(confusion_matrix(df1[1300], pred_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5003280839895013\n",
      "[[1525 1523]\n",
      " [   0    0]]\n"
     ]
    }
   ],
   "source": [
    "pred_x = lrf2.predict(x1)\n",
    "print(accuracy_score(df1[1300], pred_x))\n",
    "print(confusion_matrix(df1[1300], pred_x))\n",
    "pred_x = pd.DataFrame(pred_x)\n",
    "pred_x[1] = df1com\n",
    "pred_x[2] = df1prot\n",
    "pred_x.to_excel('../data2/hasil_pred/RF2000n_mbalinda.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5003280839895013\n",
      "[[1525 1523]\n",
      " [   0    0]]\n"
     ]
    }
   ],
   "source": [
    "lrandom_grid = {'n_estimators': [500],\n",
    "               'max_features': ['auto'],\n",
    "               #'max_depth': max_depth,\n",
    "               'min_samples_split': [2],\n",
    "               'min_samples_leaf': [1],\n",
    "               'bootstrap': [True]}\n",
    "lrf3 = RandomForestClassifier()\n",
    "lrf3 = GridSearchCV(lrf3, lrandom_grid, n_jobs=-1, cv=5)\n",
    "lrf3.fit(X, Y)\n",
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = lrf3.predict(x1)\n",
    "print(accuracy_score(df1[1300], pred_x))\n",
    "print(confusion_matrix(df1[1300], pred_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5003280839895013\n",
      "[[1525 1523]\n",
      " [   0    0]]\n"
     ]
    }
   ],
   "source": [
    "pred_x = lrf3.predict(x1)\n",
    "print(accuracy_score(df1[1300], pred_x))\n",
    "print(confusion_matrix(df1[1300], pred_x))\n",
    "pred_x = pd.DataFrame(pred_x)\n",
    "pred_x[1] = df1com\n",
    "pred_x[2] = df1prot\n",
    "pred_x.to_excel('../data2/hasil_pred/RF500n_mbalinda.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[[1524 1524]\n",
      " [   0    0]]\n"
     ]
    }
   ],
   "source": [
    "lrandom_grid = {'n_estimators': [200],\n",
    "               'max_features': ['auto'],\n",
    "               #'max_depth': max_depth,\n",
    "               'min_samples_split': [2],\n",
    "               'min_samples_leaf': [1],\n",
    "               'bootstrap': [True]}\n",
    "lrf4 = RandomForestClassifier()\n",
    "lrf4 = GridSearchCV(lrf4, lrandom_grid, n_jobs=-1, cv=5)\n",
    "lrf4.fit(X, Y)\n",
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = lrf4.predict(x1)\n",
    "print(accuracy_score(df1[1300], pred_x))\n",
    "print(confusion_matrix(df1[1300], pred_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[[1524 1524]\n",
      " [   0    0]]\n"
     ]
    }
   ],
   "source": [
    "pred_x = lrf4.predict(x1)\n",
    "print(accuracy_score(df1[1300], pred_x))\n",
    "print(confusion_matrix(df1[1300], pred_x))\n",
    "pred_x = pd.DataFrame(pred_x)\n",
    "pred_x[1] = df1com\n",
    "pred_x[2] = df1prot\n",
    "pred_x.to_excel('../data2/hasil_pred/RF200n_mbalinda.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[[1524 1524]\n",
      " [   0    0]]\n"
     ]
    }
   ],
   "source": [
    "lrandom_grid = {'n_estimators': [100],\n",
    "               'max_features': ['auto'],\n",
    "               #'max_depth': max_depth,\n",
    "               'min_samples_split': [2],\n",
    "               'min_samples_leaf': [1],\n",
    "               'bootstrap': [True]}\n",
    "lrf5 = RandomForestClassifier()\n",
    "lrf5 = GridSearchCV(lrf5, lrandom_grid, n_jobs=-1, cv=5)\n",
    "lrf5.fit(X, Y)\n",
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = lrf5.predict(x1)\n",
    "print(accuracy_score(df1[1300], pred_x))\n",
    "print(confusion_matrix(df1[1300], pred_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[[1524 1524]\n",
      " [   0    0]]\n"
     ]
    }
   ],
   "source": [
    "pred_x = lrf5.predict(x1)\n",
    "print(accuracy_score(df1[1300], pred_x))\n",
    "print(confusion_matrix(df1[1300], pred_x))\n",
    "pred_x = pd.DataFrame(pred_x)\n",
    "pred_x[1] = df1com\n",
    "pred_x[2] = df1prot\n",
    "pred_x.to_excel('../data2/hasil_pred/RF100n_mbalinda.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5843175853018373\n",
      "[[1781 1267]\n",
      " [   0    0]]\n"
     ]
    }
   ],
   "source": [
    "lrandom_grid = {'n_estimators': [10],\n",
    "               'max_features': ['auto'],\n",
    "               #'max_depth': max_depth,\n",
    "               'min_samples_split': [2],\n",
    "               'min_samples_leaf': [1],\n",
    "               'bootstrap': [True]}\n",
    "lrf6 = RandomForestClassifier()\n",
    "lrf6 = GridSearchCV(lrf6, lrandom_grid, n_jobs=-1, cv=5)\n",
    "lrf6.fit(X, Y)\n",
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = lrf6.predict(x1)\n",
    "print(accuracy_score(df1[1300], pred_x))\n",
    "print(confusion_matrix(df1[1300], pred_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5843175853018373\n",
      "[[1781 1267]\n",
      " [   0    0]]\n"
     ]
    }
   ],
   "source": [
    "pred_x = lrf6.predict(x1)\n",
    "print(accuracy_score(df1[1300], pred_x))\n",
    "print(confusion_matrix(df1[1300], pred_x))\n",
    "pred_x = pd.DataFrame(pred_x)\n",
    "pred_x[1] = df1com\n",
    "pred_x[2] = df1prot\n",
    "pred_x.to_excel('../data2/hasil_pred/RF10n_mbalinda.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5793963254593176\n",
      "[[1766 1282]\n",
      " [   0    0]]\n"
     ]
    }
   ],
   "source": [
    "lrandom_grid = {'n_estimators': [50],\n",
    "               'max_features': ['auto'],\n",
    "               #'max_depth': max_depth,\n",
    "               'min_samples_split': [2],\n",
    "               'min_samples_leaf': [1],\n",
    "               'bootstrap': [True]}\n",
    "lrf7 = RandomForestClassifier()\n",
    "lrf7 = GridSearchCV(lrf7, lrandom_grid, n_jobs=-1, cv=5)\n",
    "lrf7.fit(X, Y)\n",
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = lrf7.predict(x1)\n",
    "print(accuracy_score(df1[1300], pred_x))\n",
    "print(confusion_matrix(df1[1300], pred_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5793963254593176\n",
      "[[1766 1282]\n",
      " [   0    0]]\n"
     ]
    }
   ],
   "source": [
    "pred_x = lrf7.predict(x1)\n",
    "print(accuracy_score(df1[1300], pred_x))\n",
    "print(confusion_matrix(df1[1300], pred_x))\n",
    "pred_x = pd.DataFrame(pred_x)\n",
    "pred_x[1] = df1com\n",
    "pred_x[2] = df1prot\n",
    "pred_x.to_excel('../data2/hasil_pred/RF50n_mbalinda.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf2 = RandomForestClassifier()\n",
    "rf2 = GridSearchCV(rf2, random_grid, n_jobs=-1, cv=5,scoring='auc')\n",
    "rf2.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = rf2.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf3 = RandomForestClassifier()\n",
    "rf3 = GridSearchCV(rf3, random_grid, n_jobs=-1, cv=5,scoring='f-measure')\n",
    "rf3.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#mlp_model2 = pickle.load(open('newdesc2_MLP0_normall', 'rb'))\n",
    "pred_x = rf3.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(max_iter=1000)\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=1281, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=1281, init='normal', activation='relu'))\n",
    "    model.add(Dense(30, init='normal', activation='relu'))\n",
    "    model.add(Dense(1, init='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_model, nb_epoch=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05, 0.1, 0.5],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfa = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=5)\n",
    "clfa.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x = clfa.predict(x)\n",
    "print(accuracy_score(df0[1300], pred_x))\n",
    "print(confusion_matrix(df0[1300], pred_x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
